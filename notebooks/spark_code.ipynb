{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "import sys\n",
    "from time import time\n",
    "import json\n",
    "import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "\n",
    "# creation of spark context objects\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '8g')\n",
    "SparkContext.setSystemProperty('spark.driver.memory', '8g')\n",
    "conf = SparkConf().setAppName('task1').setMaster('local[*]')\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel('ERROR')\n",
    "input_file = sys.argv[1]\n",
    "sqlContext = SQLContext(sc)\n",
    "## input json files\n",
    "lines = sc.textFile(\"gs://kiana-bucket/kiana-data/.\",6)\n",
    "\n",
    "\n",
    "### create rdd and filter out data based on the most occuring macids\n",
    "rdd=lines.map(lambda x:json.loads(x))\n",
    "rdd.map(lambda x:x['Building'] ).count()\n",
    "\n",
    "rdd.map(lambda x : (x['ClientMacAddr'],1)).reduceByKey(add).sortBy(lambda x : (x[1]),ascending=False).take(2)\n",
    "\n",
    "rdd.map(lambda x : (x['ClientMacAddr'],1)).reduceByKey(add).count()\n",
    "rdd.map(lambda x : (x['ClientMacAddr'],1)).reduceByKey(add).filter(lambda x:(x[1]>50)).count()\n",
    "final_rdd = rdd.map(lambda x : (x['ClientMacAddr'],1)).reduceByKey(add).filter(lambda x:(x[1]>50))\n",
    "#df_data= sqlContext.read.json(input_file,multiLine=True)\n",
    "\n",
    "#converting the rdd to dataframe\n",
    "df_data = final_rdd.toDF()\n",
    "\n",
    "'''\n",
    "root\n",
    " |-- Building: string (nullable = true)\n",
    " |-- ClientMacAddr: string (nullable = true)\n",
    " |-- Level: string (nullable = true)\n",
    " |-- lat: double (nullable = true)\n",
    " |-- lng: double (nullable = true)\n",
    " |-- localtime: string (nullable = true)\n",
    "\n",
    "None\n",
    "\n",
    "'''\n",
    "\n",
    "# {\"Building\":\"TECA-IMP\",\"Level\":\"Level 1\",\"ClientMacAddr\":\"3c:a8:2a:78:82:c0\",\"lat\":-22.827847379110437,\"lng\":-43.246247836804116,\"localtime\":\"2019-09-22 20:25:31.207 UTC\"}\n",
    "'''\n",
    "+-----------------+------+\n",
    "|    ClientMacAddr| count|\n",
    "+-----------------+------+\n",
    "|20:b3:99:e4:e9:39|147515|\n",
    "|20:b3:99:e4:e9:38|146635|\n",
    "|fc:2d:5e:49:7d:4b|139633|\n",
    "|b4:c7:99:84:01:81|112582|\n",
    "|b4:c7:99:84:01:80|112484|\n",
    "|3c:a8:2a:78:d9:10|105316|\n",
    "|3c:a8:2a:78:88:10|104652|\n",
    "|b4:b5:2f:44:4a:50|100639|\n",
    "|3c:a8:2a:78:82:d0| 93355|\n",
    "|3c:a8:2a:78:93:50| 92190|\n",
    "|20:b3:99:e4:fa:59| 86273|\n",
    "|20:b3:99:e4:3a:04| 85942|\n",
    "|20:b3:99:e4:fa:58| 84230|\n",
    "|3c:a8:2a:78:91:50| 81461|\n",
    "|3c:a8:2a:78:82:c0| 64853|\n",
    "|50:3e:aa:31:1b:26| 64729|\n",
    "|b4:b5:2f:44:4a:40| 62124|\n",
    "|3c:a8:2a:78:88:00| 59787|\n",
    "|20:b3:99:e4:3c:28| 58719|\n",
    "|28:80:23:32:26:c0| 56981|\n",
    "+-----------------+------+\n",
    "only showing top 20 rows\n",
    "\n",
    "None\n",
    "'''\n",
    "### converting the localtime column to date format\n",
    "#print(\"dataframe\",df_data.show())\n",
    "df = df_data.select('Building','ClientMacAddr','Level','lat','lng', F.from_unixtime(F.unix_timestamp('localtime', 'yyyy-MM-dd HH:mm:ss')))\n",
    "#print(\"df dataframe\",df.show())\n",
    "#print(\"dataframe type\",df)\n",
    "\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.functions import from_unixtime\n",
    "df2 = df_data.select('Building','ClientMacAddr','Level','lat','lng', from_unixtime(unix_timestamp('localtime', 'MM/dd/yyy')).alias('date'))\n",
    "##print(\"df2 dataframe\",df2.show())\n",
    "#print(\"dataframe type\",df2)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "#df= df_data.withColumn('localtime',F.unix_timestamp('localtime', \"yyyy-MM-dd HH:mm:ss UTC\").cast(TimestampType()).alias(\"timestamp\"))\n",
    "#df= df_data.withColumn('localtime',F.unix_timestamp('localtime', \"yyyy-MM-dd HH:mm:ss UTC\"))\n",
    "#df = df_data.select(*,unix_timestamp(df_data.localtime, 'yyyy-MM-dd HH:mm:ss UTC').cast(TimestampType()).alias(\"localtime\"))\n",
    "### Convert dateformat of localtime column\n",
    "#\n",
    "#func =  udf (datetime.datetime(2019,8,1,3,0,0,0, datetime.timezone.utc ))\n",
    "\n",
    "# Function to covert string to datetime\n",
    "'''\n",
    "dateCol = udf(lambda z: convert(z))\n",
    "sqlContext.udf.register(\"dateCol\", dateCol) \n",
    "def convert(date_time): \n",
    "    format = 'yyyy-MM-dd HH:mm:ss UTC' # The format \n",
    "    datetime_str = datetime.strptime(date_time, format) \n",
    "   \n",
    "    return datetime_str\n",
    "\n",
    "# 2019-08-01 03:20:05.132000+00:00\n",
    "df = df_data.withColumn('localtime',dateCol('localtime') )\n",
    "\n",
    "df = df_data.select('Building','ClientMacAddr','Level','lat','lng', from_unixtime(unix_timestamp('localtime', 'yyyy-MM-dd HH:mm:ssXXXXX')).alias('localtime'))\n",
    "\n",
    "\n",
    "'''\n",
    "from dateutil import parser, tz\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "utc_zone =  tz.gettz('UTC')\n",
    "func =  udf (lambda x: datetime.strptime(x, '%y-%m-%d HH:mm:ssXXXX '), DateType())\n",
    "df = df_data.withColumn(\"localtime\",func(col(\"localtime\")))\n",
    "\n",
    "##print(df.groupBy(\"ClientMacAddr\").count().filter(\"`count` >= 200\").orderBy('count', ascending=False).show())\n",
    "\n",
    "## group by macid and select only mac ids occuring more than 100 times\n",
    "df1 = df_data.groupBy(\"ClientMacAddr\").count().orderBy('count', ascending=False)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Generate time series data for desired mac addresses\n",
    "from datetime import timedelta\n",
    "\n",
    "def createInitialAddresses(df, startTime):\n",
    "    endTime = startTime + timedelta(hours=1)\n",
    "    timeFrame = df[(df['localtime'] >= startTime) & (df['localtime'] < endTime)]\n",
    "    addrCounts = df['ClientMacAddr'].value_counts()[:20].to_dict()\n",
    "    return list(addrCounts.keys())\n",
    "\n",
    "def generateMacAddrLocationTimeSeries(df, addrList,starTime , endTime):\n",
    "    timeFrame = df[(df['localtime'] >= startTime) & (df['localtime'] < endTime)]\n",
    "    macAddrLocation = dict()\n",
    "    for addr in addrList:\n",
    "        macAddrLocation[addr] = []\n",
    "    \n",
    "    for time in range(0, 160, 20):\n",
    "        frameStartTime = startTime + timedelta(minutes=time)\n",
    "        frameEndTime = frameStartTime + timedelta(minutes=10)\n",
    "        frame = df[(df['localtime'] >= frameStartTime) & (df['localtime'] < frameEndTime)]\n",
    "        for addr in macAddrLocation:\n",
    "            records = frame.loc[frame['ClientMacAddr'] == addr]\n",
    "            if records.empty:\n",
    "                macAddrLocation[addr].append(None)\n",
    "            else:\n",
    "                macAddrLocation[addr].append(records.iloc[0])\n",
    "    return macAddrLocation\n",
    "        \n",
    "import datetime\n",
    "# knnGroupSoloClassifier(df, addrList)\n",
    "\n",
    "startTime = datetime.datetime(2019,8,1,3,0,0,0, datetime.timezone.utc ) \n",
    "endTime = datetime.datetime(2019,8,1,6,0,0,0, datetime.timezone.utc)\n",
    "addrList = createInitialAddresses(df, startTime)\n",
    "macAddrLocation = generateMacAddrLocationTimeSeries(df, addrList, startTime, endTime)\n",
    "#macAddrLocation\n",
    "\n",
    "# Compute distances from neighbor to neighbor\n",
    "def computeNeighborDistances(df, addrList,starTime , endTime, k_neighbors=10):\n",
    "    timeFrame = df[(df['localtime'] >= startTime) & (df['localtime'] < endTime)]\n",
    "    \n",
    "    addrList = set(addrList)\n",
    "    neighbor_distances = dict()\n",
    "    for addr in addrList:\n",
    "        neighbor_distances[addr] = dict()\n",
    "        \n",
    "    for time in range(0, 160, 20):\n",
    "        frameStartTime = startTime + timedelta(minutes=time)\n",
    "        frameEndTime = frameStartTime + timedelta(minutes=2)\n",
    "        frame = df[(df['localtime'] >= frameStartTime) & (df['localtime'] < frameEndTime)]\n",
    "        for addr in addrList:\n",
    "            addrLoc = frame.loc[frame['ClientMacAddr'] == addr][:1]\n",
    "            if addrLoc.empty:\n",
    "                neighbor_distances[addr][time] = None\n",
    "            else:\n",
    "                addrLoc = frame.loc[frame['ClientMacAddr'] == addr].iloc[0]\n",
    "                coord_1 = (addrLoc['lat'],addrLoc['lng'])\n",
    "                neighbors = []\n",
    "                visited = set()\n",
    "                visited.add(addr)\n",
    "                for m,record in frame.iterrows():\n",
    "                    d = distance.vincenty(coord_1, (record['lat'],record['lng']))\n",
    "                    if record['ClientMacAddr'] not in visited:\n",
    "                        visited.add(record['ClientMacAddr'])\n",
    "                        neighbors.append((d.m, record['ClientMacAddr']))\n",
    "                neighbors.sort()\n",
    "                neighbor_distances[addr][time] = neighbors[:k_neighbors]\n",
    "\n",
    "\n",
    "    return neighbor_distances\n",
    "        \n",
    "    \n",
    "startTime = datetime.datetime(2019,8,1,3,0,0,0, datetime.timezone.utc ) \n",
    "endTime = datetime.datetime(2019,8,1,6,0,0,0, datetime.timezone.utc)\n",
    "addrList = ['3c:a8:2a:78:83:94','a4:ee:57:bf:c5:86']\n",
    "\n",
    "neighbor_distances = computeNeighborDistances(df, addrList, startTime, endTime)\n",
    "##neighbor_distances\n",
    "\n",
    "###  Running the classifier\n",
    "def classifier(neighbor_distances, max_dist_threshold=10, occurence_threshold=5):\n",
    "    groups = dict()\n",
    "    for addr in neighbor_distances:\n",
    "        groups[addr] = []\n",
    "        neighbor_count = dict()\n",
    "        for time in neighbor_distances[addr]:\n",
    "            if neighbor_distances[addr][time]:\n",
    "                for dist, neighbor in neighbor_distances[addr][time]:\n",
    "                    if dist < max_dist_threshold:\n",
    "                        if neighbor in neighbor_count:\n",
    "                            neighbor_count[neighbor] += 1\n",
    "                        else:\n",
    "                            neighbor_count[neighbor] = 1\n",
    "        for neighbor in neighbor_count:\n",
    "            if neighbor_count[neighbor]>occurence_threshold:\n",
    "                groups[addr].append(neighbor)\n",
    "        print(neighbor_count)\n",
    "    return groups\n",
    "\n",
    "groups_by_distance= classifier(neighbor_distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
